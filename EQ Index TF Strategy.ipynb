{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equity Index Trend Following Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used for feature engineering and performance back-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ = pd.read_csv(\"TSMOM_EQ.csv\",parse_dates=True)\n",
    "EQ['Date'] = pd.to_datetime(EQ['Date'], dayfirst=True)\n",
    "EQ['month'] = EQ['Date'].astype(str).str[:7]\n",
    "#EQ = EQ.set_index('month').drop('Date',axis=1)\n",
    "EQ['total'] = EQ['TSMOM_EQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQdf = EQ.copy().drop('total',axis=1)\n",
    "\n",
    "for t in range(0,len(EQdf)):\n",
    "    if EQdf.loc[t,'TSMOM_EQ'] > 0:\n",
    "        EQdf.loc[t,'total'] = 1\n",
    "    elif EQdf.loc[t,'TSMOM_EQ'] < 0:\n",
    "        EQdf.loc[t,'total'] = 0\n",
    "    else:\n",
    "        EQdf.loc[t,'total'] = np.nan #zero % monthly return is given NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = [\"US_CPI\",\"US_PMI\",\"US_Unemp\"]\n",
    "pct_change_indicators = [\"US_CPI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_CPI = pd.read_csv(\"Features/CSV/US Macro Data.csv\",usecols=[1,2],skiprows=[0,1,2,3,4,5],names=[\"US_CPI\",\"Date\"])\n",
    "US_PMI = pd.read_csv(\"Features/CSV/US Macro Data.csv\",usecols=[7,8],skiprows=[0,1,2,3,4,5],names=[\"US_PMI\",\"Date\"])\n",
    "US_Unemp = pd.read_csv(\"Features/CSV/US Macro Data.csv\",usecols=[11,12],skiprows=[0,1,2,3,4,5],names=[\"US_Unemp\",\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set date axis\n",
    "US_CPI['Date'] = pd.to_datetime(US_CPI['Date'], dayfirst=True)\n",
    "US_CPI['month'] = US_CPI['Date'].astype(str).str[:7]\n",
    "US_CPI = US_CPI.set_index('month').drop('Date',axis=1)\n",
    "\n",
    "US_PMI['Date'] = pd.to_datetime(US_PMI['Date'], dayfirst=True)\n",
    "US_PMI['month'] = US_PMI['Date'].astype(str).str[:7]\n",
    "US_PMI = US_PMI.set_index('month').drop('Date',axis=1)\n",
    "\n",
    "US_Unemp['Date'] = pd.to_datetime(US_Unemp['Date'], dayfirst=True)\n",
    "US_Unemp['month'] = US_Unemp['Date'].astype(str).str[:7]\n",
    "US_Unemp = US_Unemp.set_index('month').drop('Date',axis=1)\n",
    "\n",
    "US_Unemp['US_Unemp'] = US_Unemp['US_Unemp'].shift(-1)\n",
    "US_PMI['US_PMI'] = US_PMI['US_PMI'].shift(-1)\n",
    "US_CPI['US_CPI'] = US_CPI['US_CPI'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging macro indicators to portfolio returns\n",
    "EQdf = EQdf.set_index(EQdf['month']).drop('month',axis=1)\n",
    "EQdf = EQdf.merge(US_CPI,how='left',on='month')\n",
    "EQdf = EQdf.merge(US_PMI,how='left',on='month')\n",
    "EQdf = EQdf.merge(US_Unemp,how='left',on='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulate Features\n",
    "EQdf['US_CPI'] = EQdf['US_CPI'].pct_change()\n",
    "EQdf['US_Unemp_change'] = EQdf['US_Unemp'].pct_change()\n",
    "EQdf['US_PMI'] = EQdf['US_PMI']-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprises in Macroeconomic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise_Indices_Names = [\"Citi US Inflation Surprise\",\"Citi EUR Inflation Surprise\",\"Citi EM Inflation Surprise\",\"Citi Global Inflation Surprise\", \"Citi APAC Inflation Surprise\",\"Citi BRIC Inflation Surprise\",\"Citi G10 Inflation Surprise\",\"Citi US Economic Surprise\",\"Citi EUR Economic Surprise\",\"Citi EM Economic Surprise\",\"Citi Global Economic Surprise\",\"Citi APAC Economic Surprise\",\"Citi BRIC Economic Surprise\",\"Citi G10 Economic Surprise\"]\n",
    "parse_names = [\"Date\",\"Citi US Inflation Surprise\",\"Citi EUR Inflation Surprise\",\"Citi EM Inflation Surprise\",\"Citi Global Inflation Surprise\", \"Citi APAC Inflation Surprise\",\"Citi BRIC Inflation Surprise\",\"Citi G10 Inflation Surprise\",\"Citi US Economic Surprise\",\"Citi EUR Economic Surprise\",\"Citi EM Economic Surprise\",\"Citi Global Economic Surprise\",\"Citi APAC Economic Surprise\",\"Citi BRIC Economic Surprise\",\"Citi G10 Economic Surprise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise_Indices = pd.read_csv(\"Features/CSV/Citi Surprise Indices.csv\",skiprows=[0,1,2,3,4,5],usecols=[0,1,3,4,5,6,7,8,9,10,11,12,13,14,15],names=parse_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is the surprise from last month same direction as this month? i would have thought this would be useful but apparently not\n",
    "#for i in Surprise_Indices_Names:\n",
    " #   for t in range(0,len(Surprise_Indices)-1):\n",
    "  #      if Surprise_Indices.loc[t+1, '{}'.format(i)] > 0 and Surprise_Indices.loc[t, '{}'.format(i)] > 0:\n",
    "   #         Surprise_Indices.loc[t+1,'{}_TrendCont'.format(i)] = 1\n",
    "    #    elif Surprise_Indices.loc[t+1, '{}'.format(i)] < 0 and Surprise_Indices.loc[t, '{}'.format(i)] < 0:\n",
    "     #       Surprise_Indices.loc[t+1,'{}_TrendCont'.format(i)] = 1\n",
    "      #  else:\n",
    "       #     Surprise_Indices.loc[t+1,'{}_TrendCont'.format(i)] = 0\n",
    "        \n",
    "#try using absolute difference - again did not help performance\n",
    "#for i in Surprise_Indices_Names:\n",
    " #   for t in range(0,len(Surprise_Indices)-1):\n",
    "  #      Surprise_Indices.loc[t+1, '{}_TrendCont'.format(i)] =  Surprise_Indices.loc[t+1, '{}'.format(i)] - Surprise_Indices.loc[t, '{}'.format(i)]\n",
    "\n",
    "for i in Surprise_Indices_Names:\n",
    "    #Surprise_Indices['{}'.format(i)] = abs(Surprise_Indices['{}'.format(i)]) #absolute value not valuable\n",
    "    Surprise_Indices['{}'.format(i)] = Surprise_Indices['{}'.format(i)].shift(1)\n",
    "    #Surprise_Indices['{}_TrendCont'.format(i)] = Surprise_Indices['{}_TrendCont'.format(i)].shift(1)\n",
    "    \n",
    "Surprise_Indices['Date'] = pd.to_datetime(Surprise_Indices['Date'], dayfirst=True)\n",
    "Surprise_Indices['month'] = Surprise_Indices['Date'].astype(str).str[:7]\n",
    "Surprise_Indices = Surprise_Indices.set_index('month').drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQdf = EQdf.merge(Surprise_Indices,how='left',on='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIX Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIX = pd.read_csv(\"Features/CSV/VIX.csv\",skiprows=[0,1,2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIX['Date'] = pd.to_datetime(VIX['Date'], dayfirst=True)\n",
    "VIX['month'] = VIX['Date'].astype(str).str[:7]\n",
    "VIX = VIX.set_index('month').drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIX['VIX Index'] = VIX['VIX Index'].shift(1)\n",
    "VIX['VIX_pctchange'] = VIX['VIX Index'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQdf = EQdf.merge(VIX,how='left',on='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equity Indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_Indices_Names = [\"MSCI_World\",\"MSCI_EM\",\"MSCI_APAC\",\"MSCI_EUR\",\"MSCI_EAFE\",\"MSCI_ACWI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_Indices = pd.read_csv(\"Features/CSV/Equity Indices (MSCI).csv\",usecols=[0,1,2,3,4,5,6],skiprows=[0,1,2,3,4,5],names=[\"Date\",\"MSCI_World\",\"MSCI_EM\",\"MSCI_APAC\",\"MSCI_EUR\",\"MSCI_EAFE\",\"MSCI_ACWI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_Indices['Date'] = pd.to_datetime(EQ_Indices['Date'], dayfirst=True)\n",
    "EQ_Indices['month'] = EQ_Indices['Date'].astype(str).str[:7]\n",
    "EQ_Indices = EQ_Indices.set_index('month').drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift factors back 1 month so no look ahead bias\n",
    "for i in EQ_Indices_Names:\n",
    "    EQ_Indices['{}'.format(i)] = EQ_Indices['{}'.format(i)].shift(1)\n",
    "for i in EQ_Indices_Names:\n",
    "    EQ_Indices['{}'.format(i)] = EQ_Indices['{}'.format(i)].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQdf = EQdf.merge(EQ_Indices,how='left',on='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Government Bond Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bond_Indices_Names = [\"US_Bond_RoR\",\"US_Bond_Yield\",\"UK_Bond_RoR\",\"UK_Bond_Yield\",\"GER_Bond_RoR\",\"GER_Bond_Yield\",\"JP_Bond_RoR\",\"JP_Bond_Yield\",\"AU_Bond_RoR\",\"AU_Bond_Yield\"]\n",
    "Bond_Indices_RoR = [\"US_Bond_RoR\",\"UK_Bond_RoR\",\"GER_Bond_RoR\",\"JP_Bond_RoR\",\"AU_Bond_RoR\"]\n",
    "Bond_Indices_Yield = [\"US_Bond_Yield\",\"UK_Bond_Yield\",\"GER_Bond_Yield\",\"JP_Bond_Yield\",\"AU_Bond_Yield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bond_Indices = pd.read_csv(\"Features/CSV/Government Bonds (Aggregate).csv\",usecols=[0,1,2,3,4,5,6,7,8,9,10],skiprows=[0,1,2,3,4,5],names=[\"Date\",\"US_Bond_RoR\",\"US_Bond_Yield\",\"UK_Bond_RoR\",\"UK_Bond_Yield\",\"GER_Bond_RoR\",\"GER_Bond_Yield\",\"JP_Bond_RoR\",\"JP_Bond_Yield\",\"AU_Bond_RoR\",\"AU_Bond_Yield\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bond_Indices['Date'] = pd.to_datetime(Bond_Indices['Date'], dayfirst=True)\n",
    "Bond_Indices['month'] = Bond_Indices['Date'].astype(str).str[:7]\n",
    "Bond_Indices = Bond_Indices.set_index('month').drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift factors back 1 month so no look ahead bias\n",
    "for i in Bond_Indices_Names:\n",
    "    Bond_Indices['{}'.format(i)] = Bond_Indices['{}'.format(i)].shift(1)\n",
    "for i in Bond_Indices_RoR: #total monthly return\n",
    "    Bond_Indices['{}'.format(i)] = Bond_Indices['{}'.format(i)].pct_change()\n",
    "#for i in Bond_Indices_Yield: #% change in yield\n",
    " #   Bond_Indices['{}_pctchange'.format(i)] = Bond_Indices['{}'.format(i)].pct_change()\n",
    "for i in Bond_Indices_Yield: #% change in yield\n",
    "    Bond_Indices['{}'.format(i)] = Bond_Indices['{}'.format(i)].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQdf = EQdf.merge(Bond_Indices,how='left',on='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yield Curve Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bond_Yields = pd.read_csv(\"Features/CSV/Bond Yields.csv\",usecols=[0,1,2,3,4,5,6,7,8,9],skiprows=[0,1,2,4,5])\n",
    "\n",
    "Bond_Yields['Date'] = pd.to_datetime(Bond_Yields['Date'], dayfirst=True)\n",
    "Bond_Yields['month'] = Bond_Yields['Date'].astype(str).str[:7]\n",
    "Bond_Yields = Bond_Yields.set_index('month').drop('Date',axis=1)\n",
    "\n",
    "#Shift factors back 1 month so no look ahead bias\n",
    "for i in list(Bond_Yields.columns):\n",
    "    Bond_Yields['{}'.format(i)] = Bond_Yields['{}'.format(i)].shift(1)\n",
    "\n",
    "Bond_Yields['US_YieldCurve'] = Bond_Yields['GT10 Govt'] - Bond_Yields['GT2 Govt']\n",
    "Bond_Yields['UK_YieldCurve'] = Bond_Yields['GTGBP10Y Govt'] - Bond_Yields['GTGBP2Y Govt']\n",
    "Bond_Yields['JP_YieldCurve'] = Bond_Yields['GTJPY10Y Govt'] - Bond_Yields['GTJPY2Y Govt']\n",
    "Bond_Yields['EU_YieldCurve'] = Bond_Yields['GTEUR10Y Govt'] - Bond_Yields['GTEUR2Y Govt']\n",
    "\n",
    "YieldCurve = Bond_Yields.iloc[:,-4:]\n",
    "\n",
    "EQdf = EQdf.merge(YieldCurve,how='left',on='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output to R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQdf_output = EQdf.copy().drop('Date',axis=1).drop('TSMOM_EQ',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NAs\n",
    "#EQdf = EQdf.dropna(subset=['total']) #remove NAs only based on a certain column\n",
    "EQdf_output.dropna().to_csv('EQ_Portfolio Returns & Macro Data.csv') #remove all NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Run R Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x):\n",
    "    if x > 0.5:\n",
    "        y = 2*((x-0.5)**2)+1\n",
    "        return y\n",
    "    elif x < 0.5:\n",
    "        y = -2*((x-0.5)**2)+1\n",
    "        return y\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def quad_downside(x):\n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    elif x<0.5:\n",
    "        y = -2*((x-0.5)**2)+1\n",
    "        return y\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "def quad_upside(x): #use when model has high precision\n",
    "    if x>=0.5:\n",
    "        y = 2*((x-0.5)**2)+1\n",
    "        return y\n",
    "    elif x<0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "def linear(x):\n",
    "    y= 2*x\n",
    "    return y\n",
    "\n",
    "def linear_downside(x):\n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    elif x<0.5:\n",
    "        return x\n",
    "\n",
    "def ReLU(x): #use for high precision models\n",
    "    if x>=0.5:\n",
    "        y = 2*x\n",
    "        return y\n",
    "    elif x<0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def binary(x):\n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    elif x<0.5:\n",
    "        return 0\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portfolio Statistics\n",
    "def port_stats_insample(returns,algo):\n",
    "    tree_predictions = pd.read_csv(\"Trend Following Return Prediction/In Sample_Tree Predictions_{}.csv\".format(algo))\n",
    "    tree_predictions['Row.names'] = tree_predictions['Row.names']-1 #Pandas is 0 based, R is 1 based\n",
    "    tree_predictions = tree_predictions.set_index(tree_predictions['Row.names'])\n",
    "\n",
    "    tree_predictions['y'] = pd.to_datetime(tree_predictions['y'], dayfirst=True)\n",
    "    tree_predictions['month'] = tree_predictions['y'].astype(str).str[:7]\n",
    "    tree_predictions = tree_predictions.set_index('month').drop('y',axis=1)\n",
    "    \n",
    "    test = tree_predictions.merge(returns,how='left',on='month')\n",
    "    test_cumlror_idx = pd.DataFrame.copy(test)\n",
    "    \n",
    "    #drawdown set up\n",
    "    test_cumlror_idx['portfolio_CumlProd'] = (1 + test_cumlror_idx[\"total\"]).cumprod()\n",
    "    test_cumlror_idx['portfolio_RollingMax'] = test_cumlror_idx[\"portfolio_CumlProd\"].expanding().max()\n",
    "    test_cumlror_idx['portfolio_DD'] = (test_cumlror_idx['portfolio_RollingMax']-test_cumlror_idx['portfolio_CumlProd'])/test_cumlror_idx['portfolio_RollingMax']\n",
    "    \n",
    "    #stats\n",
    "    asset_stats = pd.DataFrame(columns=['{}'.format(algo)])\n",
    "    asset_stats.loc[0,'{}'.format(algo)] = test['total'].mean()*(12)\n",
    "    asset_stats.loc[1,'{}'.format(algo)] = test[test['total'] != 0]['total'].std()*np.sqrt(12)\n",
    "    asset_stats.loc[2,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/asset_stats.loc[1,'{}'.format(algo)]\n",
    "    asset_stats.loc[3,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/(test[test['total']<0]['total'].std()*np.sqrt(12))\n",
    "    asset_stats.loc[4,'{}'.format(algo)] = test_cumlror_idx['portfolio_DD'].max()\n",
    "    asset_stats.loc[5,'{}'.format(algo)] = \"NA\"\n",
    "    asset_stats.loc[6,'{}'.format(algo)] = \"NA\"\n",
    "\n",
    "    asset_stats['Stat'] = ['Average Return','Vol','SR','Sortino Ratio','Max DD','Prob. of SR Improvement','SR p-value']\n",
    "    asset_stats = asset_stats.set_index('Stat')\n",
    "    return asset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enhanced Portfolio Statistics\n",
    "def enh_port_stats_insample(returns,algo,transformation):\n",
    "    tree_predictions = pd.read_csv(\"Trend Following Return Prediction/In Sample_Tree Predictions_{}.csv\".format(algo))\n",
    "    tree_predictions['multiplier'] = tree_predictions['1'].apply(transformation)\n",
    "    tree_predictions['Row.names'] = tree_predictions['Row.names']-1 #Pandas is 0 based, R is 1 based\n",
    "    tree_predictions = tree_predictions.set_index(tree_predictions['Row.names'])\n",
    "\n",
    "    tree_predictions['y'] = pd.to_datetime(tree_predictions['y'], dayfirst=True)\n",
    "    tree_predictions['month'] = tree_predictions['y'].astype(str).str[:7]\n",
    "    tree_predictions = tree_predictions.set_index('month').drop('y',axis=1)\n",
    "    \n",
    "    test = tree_predictions.merge(returns,how='left',on='month')\n",
    "    test['total'] = test['multiplier']*test['total']\n",
    "    test_cumlror_idx = pd.DataFrame.copy(test)\n",
    "      \n",
    "    #drawdown set up\n",
    "    test_cumlror_idx['portfolio_CumlProd'] = (1 + test_cumlror_idx[\"total\"]).cumprod()\n",
    "    test_cumlror_idx['portfolio_RollingMax'] = test_cumlror_idx[\"portfolio_CumlProd\"].expanding().max()\n",
    "    test_cumlror_idx['portfolio_DD'] = (test_cumlror_idx['portfolio_RollingMax']-test_cumlror_idx['portfolio_CumlProd'])/test_cumlror_idx['portfolio_RollingMax']\n",
    "    \n",
    "    #stats\n",
    "    asset_stats = pd.DataFrame(columns=['{}'.format(algo)])\n",
    "    asset_stats.loc[0,'{}'.format(algo)] = test['total'].mean()*(12)\n",
    "    #asset_stats.loc[1,'{}'.format(algo)] = test[test['total'] != 0]['total'].std()*np.sqrt(12) #I think best to include zeros in vol calculation so ignore this row\n",
    "    asset_stats.loc[1,'{}'.format(algo)] = test['total'].std()*np.sqrt(12)\n",
    "    asset_stats.loc[2,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/asset_stats.loc[1,'{}'.format(algo)]\n",
    "    asset_stats.loc[3,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/(test[test['total']<0]['total'].std()*np.sqrt(12))\n",
    "    asset_stats.loc[4,'{}'.format(algo)] = test_cumlror_idx['portfolio_DD'].max()\n",
    "\n",
    "    #Probabilistic SR\n",
    "    lamda3 = skew(test['total'])\n",
    "    lamda4 = kurtosis(test['total'], fisher=False)\n",
    "    SR_Monthly_Enhanced = asset_stats.loc[2,'{}'.format(algo)]*1/(np.sqrt(12))\n",
    "    SR_Monthly_Regular = port_stats_insample(EQ,\"EQ\").loc['SR','EQ']*1/(np.sqrt(12))\n",
    "    T = len(test['total'])\n",
    "    A = ((SR_Monthly_Enhanced-SR_Monthly_Regular)*np.sqrt(T-1))/np.sqrt(1-(lamda3*SR_Monthly_Enhanced)+((lamda4-1)/4)*(SR_Monthly_Enhanced**2))\n",
    "    Z_A = norm.cdf(A)\n",
    "    pvalue = 1-Z_A\n",
    "    \n",
    "    asset_stats.loc[5,'{}'.format(algo)] = Z_A\n",
    "    asset_stats.loc[6,'{}'.format(algo)] = pvalue\n",
    "    \n",
    "    asset_stats['Stat'] = ['Average Return','Vol','SR','Sortino Ratio','Max DD','Prob. of SR Improvement','SR p-value']\n",
    "    asset_stats = asset_stats.set_index('Stat')\n",
    "    return asset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_stats_insample(transformation):  \n",
    "    finalstats = port_stats_insample(EQ,\"EQ\").merge(enh_port_stats_insample(EQ,\"EQ\",transformation),how='left',on='Stat')\n",
    "    finalstats = finalstats.merge(enh_port_stats_insample(EQ,\"EQ1\",transformation),how='left',on='Stat')\n",
    "    finalstats = finalstats.merge(enh_port_stats_insample(EQ,\"EQ2\",transformation),how='left',on='Stat')\n",
    "    return finalstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EQ_x</th>\n",
       "      <th>EQ_y</th>\n",
       "      <th>EQ1</th>\n",
       "      <th>EQ2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average Return</th>\n",
       "      <td>0.159379</td>\n",
       "      <td>0.276302</td>\n",
       "      <td>0.332083</td>\n",
       "      <td>0.285372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vol</th>\n",
       "      <td>0.261216</td>\n",
       "      <td>0.193747</td>\n",
       "      <td>0.154888</td>\n",
       "      <td>0.202806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>0.610143</td>\n",
       "      <td>1.4261</td>\n",
       "      <td>2.14402</td>\n",
       "      <td>1.40712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino Ratio</th>\n",
       "      <td>1.02974</td>\n",
       "      <td>1.39417</td>\n",
       "      <td>7.54673</td>\n",
       "      <td>1.93633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max DD</th>\n",
       "      <td>0.534897</td>\n",
       "      <td>0.274726</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.33471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob. of SR Improvement</th>\n",
       "      <td>NA</td>\n",
       "      <td>0.996431</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR p-value</th>\n",
       "      <td>NA</td>\n",
       "      <td>0.0035694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00231867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             EQ_x       EQ_y       EQ1         EQ2\n",
       "Stat                                                              \n",
       "Average Return           0.159379   0.276302  0.332083    0.285372\n",
       "Vol                      0.261216   0.193747  0.154888    0.202806\n",
       "SR                       0.610143     1.4261   2.14402     1.40712\n",
       "Sortino Ratio             1.02974    1.39417   7.54673     1.93633\n",
       "Max DD                   0.534897   0.274726    0.0453     0.33471\n",
       "Prob. of SR Improvement        NA   0.996431         1    0.997681\n",
       "SR p-value                     NA  0.0035694         0  0.00231867"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_stats_insample(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of sample performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be used only once models have been decided by in sample tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portfolio Statistics\n",
    "def port_stats(returns,algo):\n",
    "    tree_predictions = pd.read_csv(\"Trend Following Return Prediction/Tree Predictions_{}.csv\".format(algo))\n",
    "    tree_predictions['Row.names'] = tree_predictions['Row.names']-1 #Pandas is 0 based, R is 1 based\n",
    "    tree_predictions = tree_predictions.set_index(tree_predictions['Row.names'])\n",
    "\n",
    "    tree_predictions['y'] = pd.to_datetime(tree_predictions['y'], dayfirst=True)\n",
    "    tree_predictions['month'] = tree_predictions['y'].astype(str).str[:7]\n",
    "    tree_predictions = tree_predictions.set_index('month').drop('y',axis=1)\n",
    "    \n",
    "    test = tree_predictions.merge(returns,how='left',on='month')\n",
    "    test_cumlror_idx = pd.DataFrame.copy(test)\n",
    "    \n",
    "    #drawdown set up\n",
    "    test_cumlror_idx['portfolio_CumlProd'] = (1 + test_cumlror_idx[\"total\"]).cumprod()\n",
    "    test_cumlror_idx['portfolio_RollingMax'] = test_cumlror_idx[\"portfolio_CumlProd\"].expanding().max()\n",
    "    test_cumlror_idx['portfolio_DD'] = (test_cumlror_idx['portfolio_RollingMax']-test_cumlror_idx['portfolio_CumlProd'])/test_cumlror_idx['portfolio_RollingMax']\n",
    "    \n",
    "    #stats\n",
    "    asset_stats = pd.DataFrame(columns=['{}'.format(algo)])\n",
    "    asset_stats.loc[0,'{}'.format(algo)] = test['total'].mean()*(12)\n",
    "    asset_stats.loc[1,'{}'.format(algo)] = test[test['total'] != 0]['total'].std()*np.sqrt(12)\n",
    "    asset_stats.loc[2,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/asset_stats.loc[1,'{}'.format(algo)]\n",
    "    asset_stats.loc[3,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/(test[test['total']<0]['total'].std()*np.sqrt(12))\n",
    "    asset_stats.loc[4,'{}'.format(algo)] = test_cumlror_idx['portfolio_DD'].max()\n",
    "    asset_stats.loc[5,'{}'.format(algo)] = \"NA\"\n",
    "    asset_stats.loc[6,'{}'.format(algo)] = \"NA\"\n",
    "\n",
    "    asset_stats['Stat'] = ['Average Return','Vol','SR','Sortino Ratio','Max DD','Prob. of SR Improvement','SR p-value']\n",
    "    asset_stats = asset_stats.set_index('Stat')\n",
    "    test.to_csv(\"Portfolio Output_Original.csv.csv\")\n",
    "    return asset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enhanced Portfolio Statistics\n",
    "def enh_port_stats(returns,algo,transformation):\n",
    "    tree_predictions = pd.read_csv(\"Trend Following Return Prediction/Tree Predictions_{}.csv\".format(algo))\n",
    "    tree_predictions['multiplier'] = tree_predictions['1'].apply(transformation)\n",
    "    tree_predictions['Row.names'] = tree_predictions['Row.names']-1 #Pandas is 0 based, R is 1 based\n",
    "    tree_predictions = tree_predictions.set_index(tree_predictions['Row.names'])\n",
    "\n",
    "    tree_predictions['y'] = pd.to_datetime(tree_predictions['y'], dayfirst=True)\n",
    "    tree_predictions['month'] = tree_predictions['y'].astype(str).str[:7]\n",
    "    tree_predictions = tree_predictions.set_index('month').drop('y',axis=1)\n",
    "    \n",
    "    test = tree_predictions.merge(returns,how='left',on='month')\n",
    "    test['total'] = test['multiplier']*test['total']\n",
    "    test_cumlror_idx = pd.DataFrame.copy(test)\n",
    "      \n",
    "    #drawdown set up\n",
    "    test_cumlror_idx['portfolio_CumlProd'] = (1 + test_cumlror_idx[\"total\"]).cumprod()\n",
    "    test_cumlror_idx['portfolio_RollingMax'] = test_cumlror_idx[\"portfolio_CumlProd\"].expanding().max()\n",
    "    test_cumlror_idx['portfolio_DD'] = (test_cumlror_idx['portfolio_RollingMax']-test_cumlror_idx['portfolio_CumlProd'])/test_cumlror_idx['portfolio_RollingMax']\n",
    "    \n",
    "    #stats\n",
    "    asset_stats = pd.DataFrame(columns=['{}'.format(algo)])\n",
    "    asset_stats.loc[0,'{}'.format(algo)] = test['total'].mean()*(12)\n",
    "    #asset_stats.loc[1,'{}'.format(algo)] = test[test['total'] != 0]['total'].std()*np.sqrt(12) #I think best to include zeros in vol calculation so ignore this row\n",
    "    asset_stats.loc[1,'{}'.format(algo)] = test['total'].std()*np.sqrt(12)\n",
    "    asset_stats.loc[2,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/asset_stats.loc[1,'{}'.format(algo)]\n",
    "    asset_stats.loc[3,'{}'.format(algo)] = asset_stats.loc[0,'{}'.format(algo)]/(test[test['total']<0]['total'].std()*np.sqrt(12))\n",
    "    asset_stats.loc[4,'{}'.format(algo)] = test_cumlror_idx['portfolio_DD'].max()\n",
    "\n",
    "    #Probabilistic SR\n",
    "    lamda3 = skew(test['total'])\n",
    "    lamda4 = kurtosis(test['total'], fisher=False)\n",
    "    SR_Monthly_Enhanced = asset_stats.loc[2,'{}'.format(algo)]*1/(np.sqrt(12))\n",
    "    SR_Monthly_Regular = port_stats(EQ,\"EQ\").loc['SR','EQ']*1/(np.sqrt(12))\n",
    "    T = len(test['total'])\n",
    "    A = ((SR_Monthly_Enhanced-SR_Monthly_Regular)*np.sqrt(T-1))/np.sqrt(1-(lamda3*SR_Monthly_Enhanced)+((lamda4-1)/4)*(SR_Monthly_Enhanced**2))\n",
    "    Z_A = norm.cdf(A)\n",
    "    pvalue = 1-Z_A\n",
    "    \n",
    "    asset_stats.loc[5,'{}'.format(algo)] = Z_A\n",
    "    asset_stats.loc[6,'{}'.format(algo)] = pvalue\n",
    "    \n",
    "    asset_stats['Stat'] = ['Average Return','Vol','SR','Sortino Ratio','Max DD','Prob. of SR Improvement','SR p-value']\n",
    "    asset_stats = asset_stats.set_index('Stat')\n",
    "    test.to_csv(\"Portfolio Output_{}.csv\".format(algo))\n",
    "    return asset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust according to model selected from in sample tuning\n",
    "def final_stats(transformation):  \n",
    "    finalstats = port_stats(EQ,\"EQ\").merge(enh_port_stats(EQ,\"EQ_Tree\",transformation),how='left',on='Stat')\n",
    "    finalstats = finalstats.merge(enh_port_stats(EQ,\"EQ_RF\",transformation),how='left',on='Stat')\n",
    "    finalstats = finalstats.merge(enh_port_stats(EQ,\"EQ_AB\",transformation),how='left',on='Stat')\n",
    "    finalstats = finalstats.merge(enh_port_stats(EQ,\"EQ_Bag\",transformation),how='left',on='Stat')\n",
    "    finalstats = finalstats.merge(enh_port_stats(EQ,\"EQ_NNet\",transformation),how='left',on='Stat')\n",
    "    return finalstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EQ</th>\n",
       "      <th>EQ_Tree</th>\n",
       "      <th>EQ_RF</th>\n",
       "      <th>EQ_AB</th>\n",
       "      <th>EQ_Bag</th>\n",
       "      <th>EQ_NNet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average Return</th>\n",
       "      <td>-0.0492857</td>\n",
       "      <td>0.0182743</td>\n",
       "      <td>0.09168</td>\n",
       "      <td>0.0311143</td>\n",
       "      <td>0.0753429</td>\n",
       "      <td>0.0178457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vol</th>\n",
       "      <td>0.269631</td>\n",
       "      <td>0.16299</td>\n",
       "      <td>0.100797</td>\n",
       "      <td>0.158488</td>\n",
       "      <td>0.17065</td>\n",
       "      <td>0.173061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>-0.18279</td>\n",
       "      <td>0.112119</td>\n",
       "      <td>0.909553</td>\n",
       "      <td>0.19632</td>\n",
       "      <td>0.441505</td>\n",
       "      <td>0.103118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino Ratio</th>\n",
       "      <td>-0.195459</td>\n",
       "      <td>0.0710516</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.171451</td>\n",
       "      <td>0.413221</td>\n",
       "      <td>0.0640507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max DD</th>\n",
       "      <td>0.719069</td>\n",
       "      <td>0.312132</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.241156</td>\n",
       "      <td>0.243669</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob. of SR Improvement</th>\n",
       "      <td>NA</td>\n",
       "      <td>0.752233</td>\n",
       "      <td>0.997599</td>\n",
       "      <td>0.808437</td>\n",
       "      <td>0.91695</td>\n",
       "      <td>0.745757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR p-value</th>\n",
       "      <td>NA</td>\n",
       "      <td>0.247767</td>\n",
       "      <td>0.00240089</td>\n",
       "      <td>0.191563</td>\n",
       "      <td>0.0830505</td>\n",
       "      <td>0.254243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                EQ    EQ_Tree       EQ_RF      EQ_AB  \\\n",
       "Stat                                                                   \n",
       "Average Return          -0.0492857  0.0182743     0.09168  0.0311143   \n",
       "Vol                       0.269631    0.16299    0.100797   0.158488   \n",
       "SR                        -0.18279   0.112119    0.909553    0.19632   \n",
       "Sortino Ratio            -0.195459  0.0710516    0.891071   0.171451   \n",
       "Max DD                    0.719069   0.312132      0.0855   0.241156   \n",
       "Prob. of SR Improvement         NA   0.752233    0.997599   0.808437   \n",
       "SR p-value                      NA   0.247767  0.00240089   0.191563   \n",
       "\n",
       "                            EQ_Bag    EQ_NNet  \n",
       "Stat                                           \n",
       "Average Return           0.0753429  0.0178457  \n",
       "Vol                        0.17065   0.173061  \n",
       "SR                        0.441505   0.103118  \n",
       "Sortino Ratio             0.413221  0.0640507  \n",
       "Max DD                    0.243669      0.268  \n",
       "Prob. of SR Improvement    0.91695   0.745757  \n",
       "SR p-value               0.0830505   0.254243  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats(binary).to_csv(\"Performance Metrics Table.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
